---
title: "FAQ Generator"
collection: portfolio
---

* Fine-tuned (supervised instruction) Llama-3 8b, Llama-2 7b, Mistral 7b, T5, and BART to generate FAQs based on the website’s content.
* Performed QLoRA PEFT on Llama-3 and Llama-2 to enhance the quality of the generated FAQs.
* Scrapped (API call) and stored the top 150 US universities’ MS in CS graduate admission requirements in a JSON file (dataset creation).
* Achieved a 10% increase in accuracy/relevance of generated FAQs compared to a baseline T5 transformer.

# ✦ [Code](https://github.com/SudarshanaSRao/CSCI-499_final_project) ✦ 

# ✦ [Medium blog](https://medium.com/@sudarshanasrao/faq-generation-using-large-language-models-88746c9381a6) ✦

<!-- This is an item in your portfolio. It can be have images or nice text. If you name the file .md, it will be parsed as markdown. If you name the file .html, it will be parsed as HTML.  -->
